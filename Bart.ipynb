{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install datasets\n",
        "#!pip install py7zr\n",
        "#! pip install -U accelerate\n",
        "#! pip install -U transformers"
      ],
      "metadata": {
        "id": "S4X6f74F-OZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#train"
      ],
      "metadata": {
        "id": "uNOGVgpmqpYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer ,DataCollatorForSeq2Seq\n",
        "from datasets import load_dataset, load_from_disk, load_metric\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "9Hpd8NPP9vsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data_cnn(data_to_process):\n",
        "    #get all the dialogues\n",
        "    inputs = [dialogue for dialogue in data_to_process['article']]\n",
        "    #tokenize the dialogues\n",
        "    model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n",
        "    #tokenize the summaries\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        targets = tokenizer(data_to_process['highlights'], max_length=max_target, padding='max_length', truncation=True)\n",
        "\n",
        "    #set labels\n",
        "    model_inputs['labels'] = targets['input_ids']\n",
        "    #return the tokenized data\n",
        "    #input_ids, attention_mask and labels\n",
        "    return model_inputs\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "YqZ1P3QekWVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric(\"rouge\")\n",
        "max_input = 512\n",
        "max_target = 128\n",
        "batch_size = 8\n",
        "model_checkpoints = \"facebook/bart-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "DJK73lhxkhZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_cnn = load_from_disk('/content/drive/MyDrive/dataset/cnn/train')\n",
        "test_dataset_cnn = load_from_disk('/content/drive/MyDrive/dataset/cnn/test')\n",
        "validation_dataset_cnn = load_from_disk('/content/drive/MyDrive/dataset/cnn/validation')\n",
        "tokenize_data_cnn_train = train_dataset_cnn.map(preprocess_data_cnn, batched = True)\n",
        "tokenize_data_cnn_test = test_dataset_cnn.map(preprocess_data_cnn, batched = True)\n",
        "tokenize_data_cnn_validation = validation_dataset_cnn.map(preprocess_data_cnn, batched = True)"
      ],
      "metadata": {
        "id": "xDVkqewqnoCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset_cnn[8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdEiS3-3oX2-",
        "outputId": "1449d033-bd39-42fa-8885-85a3cf150524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article': '(CNN)Filipinos are being warned to be on guard for flash floods and landslides as tropical storm Maysak approached the Asian island nation Saturday. Just a few days ago, Maysak gained super typhoon status thanks to its sustained 150 mph winds. It has since lost a lot of steam as it has spun west in the Pacific Ocean. It\\'s now classified as a tropical storm, according to the Philippine national weather service, which calls it a different name, Chedeng. It boasts steady winds of more than 70 mph (115 kph) and gusts up to 90 mph as of 5 p.m. (5 a.m. ET) Saturday. Still, that doesn\\'t mean Maysak won\\'t pack a wallop. Authorities took preemptive steps to keep people safe such as barring outdoor activities like swimming, surfing, diving and boating in some locales, as well as a number of precautionary evacuations. Gabriel Llave, a disaster official, told PNA that tourists who arrive Saturday in and around the coastal town of Aurora \"will not be accepted by the owners of hotels, resorts, inns and the like ... and will be advised to return to their respective places.\" Aldczar Aurelio, a meteorologist with the Philippine Atmospheric, Geophysical and Astronomical Services Administration (PAGASA), said the storm was centered 200 miles southwest of Aurora province as of 5 p.m. (5 a.m. ET) and heading west at a 12.5 mph clip. It\\'s expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday. Ahead of the storm. Isabela Gov. Faustino Dry III warned Saturday that residents should act as if this will be \"no ordinary typhoon.\" Dry told PNA, \"We do not know what the impact will be once it will make landfall.\"', 'highlights': 'Once a super typhoon, Maysak is now a tropical storm with 70 mph winds . It could still cause flooding, landslides and other problems in the Philippines .', 'id': '6222f33c2c79b80be437335eeb3f488509e92cf5'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(\n",
        "    '/storage/changyu/results/bart', #save directory\n",
        "    evaluation_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=3,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True,\n",
        "    eval_accumulation_steps=3,\n",
        "    fp16=True, #available only with CUDA\n",
        "    save_steps=500,\n",
        "    save_total_limit=10,\n",
        "    logging_first_step=True,\n",
        "    logging_steps=500,\n",
        "    #generation_max_length=128,\n",
        "    )\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenize_data_cnn_train, #tokenize_data_cnn_train,\n",
        "    eval_dataset=tokenize_data_cnn_validation, #tokenize_data_cnn_validation,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "TpARax8t_PjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "vcCyH4JI_XrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate model"
      ],
      "metadata": {
        "id": "jVzKygP6lEf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model on test dataset\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    #train_dataset=tokenize_data_cnn_train, #tokenize_data_cnn_train,\n",
        "    eval_dataset=tokenize_data_cnn_test,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "GeKeqTQRlHw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show some examples"
      ],
      "metadata": {
        "id": "q831o0SRgdEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case = test_dataset_cnn[0][\"article\"]\n",
        "model_inputs = tokenizer(test_case,  max_length=max_input, padding='max_length', truncation=True)\n",
        "raw_pred, _, _ = trainer.predict([model_inputs])\n",
        "print(tokenizer.decode(raw_pred[0]))"
      ],
      "metadata": {
        "id": "0Jj62DH_lVJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first example result:\n",
        "The Palestinian Authority officially becomes the 123rd member of the International Criminal Court. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January."
      ],
      "metadata": {
        "id": "Z4E0EWiyljXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_case1 = test_dataset_cnn[1][\"article\"]\n",
        "model_inputs1 = tokenizer(test_case1,  max_length=max_input, padding='max_length', truncation=True)\n",
        "raw_pred1, _, _ = trainer.predict([model_inputs1])\n",
        "print(tokenizer.decode(raw_pred1[0]))"
      ],
      "metadata": {
        "id": "uFcpf0tDlVVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second result: Mohammad Javad Zarif is the Iranian foreign minister. He has been U.S. Secretary of State John Kerry's opposite number in nuclear talks. Zarif has gone a long way to bring Iran in from the cold. Mohammad Javad Zarif is the Iranian foreign minister. He was nominated to be foreign minister by Ahmadinejad's successor, Hassan Rouhami. Zarif was outside the country during the demonstrations against the Shah of Iran."
      ],
      "metadata": {
        "id": "oI5jKBm9l1P9"
      }
    }
  ]
}